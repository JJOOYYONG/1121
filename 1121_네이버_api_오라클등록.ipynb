{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "\n",
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "client_id=\"MV6NBr8jD4HVKrnXIT6Z\"\n",
    "client_secret=\"KB0BVduyM5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CODE 1]\n",
    "def get_request_url(url):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    req.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
    "    try: \n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print (\"[%s] Url Request Success\" % datetime.datetime.now())\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CODE 2]\n",
    "def getNaverSearchResult(sNode, search_text, page_start, display):\n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % sNode\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(search_text), page_start, display)\n",
    "    #parameters = \"?query=%s\" % urllib.parse.quote(search_text)\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    retData = get_request_url(url)\n",
    "    \n",
    "    if (retData == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(retData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CODE 3]\n",
    "def getJsonData(jsonSearch,search_text):\n",
    "    jsonResult=[]\n",
    "    for post in jsonSearch['items']:\n",
    "        title = post['title']\n",
    "        description = post['description']\n",
    "        org_link = post['originallink']\n",
    "        link = post['link']\n",
    "\n",
    "    #Tue, 14 Feb 2017 18:46:00 +0900\n",
    "        pDate = datetime.datetime.strptime(post['pubDate'],'%a, %d %b %Y %H:%M:%S +0900')\n",
    "        pDate = pDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "        jsonResult.append({'title':title, 'description': description,\n",
    "                    'org_link':org_link, 'link': org_link, \n",
    "                    'pDate':pDate})\n",
    "    \n",
    "    with open('%s_naver.json' % (search_text), 'w', encoding='utf8') as outfile:\n",
    "        retJson = json.dumps(jsonResult,\n",
    "                        indent=4, sort_keys=True,\n",
    "                        ensure_ascii=False)\n",
    "        outfile.write(retJson)\n",
    "        \n",
    "    print ('%s_naver.json SAVED' % (search_text))\n",
    "        \n",
    "    return jsonResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-21 12:32:50.973415] Url Request Success\n",
      "지소미아_naver.json SAVED\n",
      "지소미아_naver.csv SAVED\n"
     ]
    }
   ],
   "source": [
    "#[CODE4]\n",
    "def getDataFrame(jsonSearch,search_text):\n",
    "    \n",
    "    titles=[];des=[];org_links=[];links=[];pDate=[]\n",
    "    for row in jsonSearch['items']:\n",
    "        titles.append(row['title'].strip().replace(u'\\xa0',''))\n",
    "        des.append(row['description'].strip().replace(u'\\xa0',''))\n",
    "        org_links.append(row['originallink'])\n",
    "        links.append(row['link'])\n",
    "\n",
    "        mDate = datetime.datetime.strptime(row['pubDate'],'%a, %d %b %Y %H:%M:%S +0900')\n",
    "        mDate = mDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        pDate.append(mDate)\n",
    "    \n",
    "    df=pd.DataFrame({'title':titles,'description':des,'org_link':org_links,'link':links,'date':pDate})\n",
    "    df.to_csv('%s_naver.csv'%(search_text),index=False)\n",
    "    print ('%s_naver.csv SAVED' % (search_text))\n",
    "    return df\n",
    "\n",
    "def oracle_save(df):\n",
    "    conn=cx_Oracle.connect('pgm/1234@localhost:1521/orcl')\n",
    "    cursor=conn.cursor()\n",
    "    sql=\"insert into search_data values(:1,:2,:3,:4,:5)\"\n",
    "    rows=[tuple(x) for x in df.values]\n",
    "    for row in rows:\n",
    "        cursor.execute(sql,row)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def main():\n",
    "    jsonResult = []\n",
    "    # 'news', 'blog', 'cafearticle'\n",
    "    sNode = 'news'\n",
    "    search_text = '지소미아'\n",
    "    display_count = 100\n",
    "    \n",
    "    \n",
    "    jsonSearch = getNaverSearchResult(sNode, search_text, 1, display_count)\n",
    "    jsonResult=getJsonData(jsonSearch, search_text)\n",
    "    \n",
    "    #while ((jsonSearch != None) and (jsonSearch['display'] != 0)):\n",
    "    df=getDataFrame(jsonSearch, search_text)\n",
    "    \n",
    "    oracle_save(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
